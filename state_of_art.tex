\chapter{State of the art}
\label{cha:art}
In this chapter, the state of the art regarding the creation of personas is presented. It is divided in four sections which reflect the main steps of the process:
\begin{enumerate}
    \item~\textbf{data collection}, which consists in getting data about the users on which personas are built;
    \item~\textbf{data enrichment}, which consists in analysing the previously collected data to extract additional insights.
    \item~\textbf{clustering}, which consists in identifying groups of similar users based on the characteristics obtained in the previous two steps;
    \item~\textbf{persona generation}, which consists in creating a persona for each identified group.
\end{enumerate}
Each section will cover the work that has been done so far, with emphasis on the latest developments in the use of enriched social media data. The current research problem of fully automating the whole process is tackled as well.

\section{Data collection}
\label{sec:collection}
In this section, the main data sources and methods used to create personas are presented in chronological order, starting from hands-on qualitative methods, followed by surveys and the latest developments with web data.

\subsection{Qualitative methods}
\label{subsec:qualitative}
Traditionally, data was collected using purely qualitative methods. Those can be split into two categories: implicit and explicit. Implicit methods are described by the concept "don't ask, observe" and include observations, field studies and, in part, usability tests~\cite{mulder2007approaches, pruitt2003personas, olsen2004persona}. Explicit methods rely instead on directly asking questions to users: the most used ones are interviews and focus groups~\cite{mulder2007approaches, pruitt2003personas, olsen2004persona}. All these interactions, whether implicit or explicit, have to be carefully crafted, usually by experts of the given research field, in order to gain useful insights to be later analysed. 

Because of their open-ended nature, qualitative methods allow researchers to explore user behaviour in depth, but they also come with some shortcomings:
\begin{itemize}
    \item~\textbf{small coverage}: the research is usually done with few users (10-20)~\cite{mulder2007approaches}. Thus, there is no evidence that personas actually represent the full user base~\cite{chapman2006personas};
    \item~\textbf{subjectivity}: interview results and related qualitative data are subjective by nature, and can also present biases from both users and researchers~\cite{mulder2007approaches}.
\end{itemize}

\subsection{Surveys}
\label{subsec:surveys}
With the aforementioned flaws in mind, the concept of data-driven personas was introduced. It consists in grounding personas in real, larger-scale data by using quantitative research methods alongside qualitative ones (or completely replacing the latter)~\cite{mulder2007approaches}. The most popular data sources to achieve this are surveys: 47\% of papers about data-driven personas development report their use~\cite{salminen2021survey}. They are easy to share, allow a broad exploration of the user base, and are easier to cluster than open-ended interview results.

R. Sinha was one among the first ones to report the use of surveys in 2003, when developing personas for a restaurant recommendation system~\cite{sinha2003persona}. She and her team crafted a survey after having identified 32 relevant dimensions of the restaurant experience, asking users to rate them on a five point Likert scale. The same approach was taken by McGinn and Kotamraju in 2008 \cite{mcginn2008data}, who spent three weeks designing a survey together with the stakeholders and got 1300 responses, much more data than qualitative methods can achieve. 

The use of surveys was further explored in an article by Tu et al. in 2010~\cite{tu2010combine}. They begin by proposing four steps for the persona creation process, with the first one reading: "\textit{gather user data (personal data, users' relationships with the product and users' goals and motivations) through large scale questionnaires and user survey}". They highlighted that the design of the questionnaire is crucial in order to get relevant dimensions for clustering, and that it should focus on capturing user behaviors, goals and motivations. To build theirs, they used a template designed by George Olsen in his article "\textit{Persona creation and usage toolkit}"~\cite{olsen2004persona}, but noted that it was difficult to fully adapt it to their situation, suggesting that a "universal" template may not exist.

\subsection{Web data}
\label{subsec:webdata}
The next development in data collection came with the popularization of web data. Almost 30\% of papers on data-driven personas report its use, and the number is increasing and surpassed that of surveys~\cite{salminen2021survey}. Web data includes sources such as social media platforms (e.g. YouTube~\cite{an2018imaginary}), online discussion forums~\cite{huh2016personas}, and online analytics (e.g. clickstream data~\cite{zhang2016data}). The increasing popularity of the web also resulted in larger datasets and survey samples, with an average size about five times that of the first surveys~\cite{salminen2021survey}.

An example of the use of online analytics was proposed by Zhang et al. in 2016~\cite{zhang2016data}. Clickstream data is defined as sequences of users' clicks (or taps) when using a product. Using it as a data source comes with the following benefits: clickstreams directly describe user behavior and workflow in a product; additionally, they are collected automatically without the need of human intervention; on top of that, the constant collection of clickstreams allows personas to be easily updated in case their workflows evolve over time. This approach is suitable when personas need to capture the user experience (e.g. e-commerce websites or smartphone applications).

\textbf{Social media} is currently being explored as a source of both demographical and behavioral data. It is a good candidate because of the ever increasing number of people who have social media accounts and share content online. The latter often includes insights into users' interests, opinions and demographics, drawing many similarities to what can be found in personas~\cite{humphrey2017user}. Furthermore, most social media sites provide APIs that allow to collect data programmatically on a large scale. At the same time, researchers who draw on social media to create personas need to be aware that the data contained in user profiles does not always represent the truth and that a large number of accounts are either fake or bots (Twitter shut down up to 70 million suspicious accounts in 2018~\cite{twitter2018suspicious}). Moreover, the concern for privacy is nowadays more relevant than ever, and researchers need to fully comply with GDPR when dealing with user data.

Research on the field is mainly done by a team led by Dr. Jim Jansen at the Qatar Computing Research Institute, through the development of \textit{APG (Automatic Persona Generation)}\footnote{\url{persona.qcri.org}}. It is a service that focuses on automatically generating personas for a YouTube channel using YouTube analytics as the main source, with data such as comments, likes and view counts grouped by type of content and demographics~\cite{an2018imaginary}. Other tools available online propose the same kind of services, focusing on online and social media analytics\footnote{\url{www.delve.ai}, \url{www.mnemonic.ai}}. This means that the user of the service needs to already have an established presence on the web (be it their website or their social media accounts) and an analytics tool to keep track of the related data (e.g. Twitter Analytics, Facebook Analytics, Google Analytics).

The use of more traditional social networks (over YouTube, which specialises almost uniquely in video content) has been explored to a lesser extent, with not much documentation available. An et al., when developing personas for Al Jazeera\footnote{\url{www.aljazeera.com}}, reported the use of Facebook and Twitter data, but with some caveats~\cite{an2016towards}. The former was limited only to URLs shared by users who followed or talked about Al Jazeera's Facebook page, since Facebook API requires explicit user consent in order to access any personal data. The latter was also limited to users' biographies, with the purpose of extracting non-behavioral aspects such as occupation and hobbies.

\section{Data enrichment}
\label{sec:enrichment}
Data enrichment has little documentation in persona literature: it became a necessary step only when social media was introduced as a data source, since information like demographics and behavior were not directly available but had to be extracted from user profiles and posts~\cite{salminen2021survey}.

There are many studies that aim at inferring user demographics from social media, especially in the field of academia research (e.g. for studying gender disparity in publications). The best results are achieved with gender and age predictions~\cite{cesare2017well}. For these purposes, many tools and APIs are available, which mainly use names or images to predict a user's most likely demographics. It should be noted though that these are only predictions, and should be treated with care in order to not introduce fake data into the final personas. Whenever possible, such predictions should be cross-validated between multiple data sources.

To infer user behavior, researchers' main approach is to determine a user's personality. Dos Santos et al. were the first to use this method, when they included the Big Five personality framework in their surveys to create a behavioral persona for a pet robot~\cite{dos2014behavioral}. Since then, a lot of research has been conducted to extract personality from social media user profiles. The first approaches only used public metrics such as the number of friends, but they turned out to be inaccurate since users typically have a large number of friends and followers regardless of their personality. Later studies focused on the way users interact with their friends, including frequency and intensity of such interactions~\cite{adali2012predicting, golbeck2011predicting}.

Another great source of information is the content of social media posts. By analyzing the text or multimedia content of a user's posts, one can not only understand the author's interests, values and opinions towards a particular topic or product, but also their preferred language, the time they are most active and their tone of voice, which are all good candidates for the definition of a persona. Several NLP (Natural Language Processing) techniques are available to extract such insights from text: semantic analysis, to identify entities (such as nouns and corresponding adjectives)~\cite{maulud2021state}; topic analysis, to either extract or assign topics and find users' topical interests~\cite{huang2013sentiment}; sentiment scoring, to understand a user's attitude towards a particular topic~\cite{neri2012sentiment, huang2013sentiment}. Deep learning solutions can be used as well to achieve similar results on images and videos~\cite{rodriguez2020personality}. It is important to consider this, as multimedia content is rapidly growing in popularity over text: according to Mark Zuckerberg, CEO and founder of Facebook: "\textit{Most of the content 10 years ago was text, and then photos, and now it’s quickly becoming videos}"\footnote{\url{www.fastcompany.com/3057024/mark-zuckerberg-soon-the-majority-of-content-we-consume-will-be-video}}.

\section{Clustering}
\label{sec:clustering}
Clustering, also known as segmentation, is a crucial step in the process of persona creation, since its output determines the number of personas and the characteristics which tell them apart.

Traditional segmentation was done by hand, and consisted in analyzing the results of data collection in order to find patterns and common themes. This approach is highly subjective and often involves researchers "listening to their guts"~\cite{mulder2007approaches}, especially if they do not have much expertise in the field they are studying.

With the advent of quantitative research for persona creation, more objective and algorithmical methods started being used. At first, dimensionality reduction techniques were employed to uncover latent patterns in survey responses. Subsequent works adopted a variety of clustering algorithms, depending on the scenario for which personas were being created. Both of the approaches are presented in the following subsections.

\subsection{Dimensionality reduction}
\label{subsec:dimrec}
As surveys can have a large number of questions (thus answers), oftentimes with latent correlations between them, it can be useful to reduce their amount while still preserving most of the insights they offer. One method to achieve this is exploratory factor analysis, a statistical technique whose goal is to identify the underlying relationships between measured variables. This method was only documented once in persona literature, by McGinn and Kotamraju in 2008~\cite{mcginn2008data}.

More popular and documented is the use of PCA (Principal Component Analysis)~\cite{salminen2021survey, sinha2003persona, tu2010combine}. It is a dimension-reducing algorithm used to extract information by removing non-essential elements with relatively fewer variations. While it was originally used on its own~\cite{sinha2003persona, tu2010combine}, most of the recent research that employs PCA does so in conjunction with the clustering algorithms presented in the following section~\cite{salminen2021survey} in order to avoid the so-called curse of dimensionality\footnote{\url{en.wikipedia.org/wiki/Curse_of_dimensionality}}.

\subsection{Clustering algorithms}
\label{subsec:clustering}
Clustering algorithms take a series of data points as input, and assign a cluster index to each one of them as output. What follows are the most popular ones employed in persona creation.

\textbf{K-Means} is an unsupervised machine learning algorithm which partitions data into $k$ clusters, where $k$ is a parameter that needs to be chosen by the user. Its goal is to find clusters in a way that data points in the same cluster are similar and data points in the different clusters are farther apart. Two things should be noted: firstly, similarity is defined by a distance metric. A common one is euclidean distance, but custom ones may have to be designed for non-trivial problems or when there is a mix of categorical and numerical data. Secondly, since the initialisation is random, results are not reproducible (this can be mitigated with an initialisation setting). In persona creation, K-Means has the flaw that the optimal number of personas $k$ is not known, requiring the use of other methods to determine it. Nonetheless, it is the most employed clustering algorithm in persona literature~\cite{salminen2021survey}.

\textbf{Non-negative matrix factorization (NMF)} is a matrix factorization method, in which a matrix $V$ ($n$ x $m$) is approximately factored into two matrices $W$ ($n$ x $r$) and $H$ ($r$ x $m$), with the property that all three matrices have no negative elements. Intuitively, the rows of $V$ represent some objects (e.g. $n$ different users), while the columns represent some properties (e.g. $m$ user attributes). The number $r$ is a parameter and is often chosen smaller than $m$ to also achieve dimensionality reduction. NMF is mainly used when dealing with interactions of users with content: a practical example is presented by An et al. for extracting behavioral patterns from interactions between customer segments and YouTube videos~\cite{an2018customer}. Their matrix $V$ had customer segments as rows and videos as columns, with each cell $V_{ij}$ containing the view count of customer group $i$ on video $j$. After factorization, they were able to extract video consumption patterns from matrix $H$ and associate customer segments to each pattern through matrix $W$.

\textbf{Hierarchical clustering (HC)} is an unsupervised machine learning algorithm which produces a hierarchical order of clusters (arranged as a tree). It is an alternative to K-Means that grants reproducible results and does not need prior knowledge of the $k$ parameter, but tends to be inefficient on large datasets both in terms of speed and memory usage. It only works well when there is an underlying hierarchical structure in the data.

\textbf{Other clustering algorithms} used in persona creation are Q-SIM and LDA. Q-SIM (Quality Similarity Clustering) was proposed by Masiero et al. in 2013 as an alternative to K-Means clustering~\cite{masiero2013automa}. Its main feature is that it replaces the hyperparameter $k$ with a number representing the desired intra-cluster similarity degree. While they evaluated Q-SIM to perform better than K-Means in their case study, the algorithm has been adopted only once in the following years~\cite{dos2014behavioral} and its implementation has not been supported further. LDA (Latent Dirichlet Allocation) is a NLP technique that can be adopted to find latent topics in text~\cite{bamman2013learning}, and therefore applies only when clustering needs to be performed on textual documents.

\section{Persona generation}
\label{sec:generation}
This last step involves building the final persona profiles, one for each cluster. The approach has remained consistent through time, regardless of the methods being employed in the previous steps (qualitative, quantitative or mixed). Since each cluster comes with characteristics that tell it apart from the others, this step boils down to "making clusters come to life"~\cite{mulder2007approaches} by giving them an identity. This is usually achieved by supplying a name, photo, demographics (if not already present in the clusters), biography, quotes and stories~\cite{mulder2007approaches}. It should be noted that, since personas are meant to be fictional, such characteristics should not be taken directly from the attributes of one or more specific users, but should be abstracted from the data itself or generated from scratch. In doing so, one needs to pay attention to coming up with coherent attributes in order for personas to be believable (e.g. not assigning a male name to a female persona~\cite{jung2021all}).

This step turned out to be problematic when dealing with the full automation of the persona creation process, a problem tackled by the APG research team referenced in Section \ref{subsec:webdata}. They mentioned some challenges: firstly, when populating their personas with user quotes, they noticed that inappropriate comments were sometimes being chosen, lowering the overall persona quality when evaluated by marketing experts~\cite{salminen2019future}. Secondly, personas need to be assigned demographically appropriate names in order to be believable. To tackle this, they proposed a tool that takes age, country of origin and gender as input and returns an appropriate name~\cite{jung2021all}. The same applies to photos: their first approach was to buy a set of stock photos to cover most demographics, but their latest works study the possibility of using AI generated pictures~\cite{salminen2020using}. Lastly, if personas are provided a textual biography, the latter should be coherent with the rest of the data. As research in the field of automatic persona creation is relatively new, they refer to the challenge of fully automating this last step as an open research problem~\cite{salminen2019future, salminen2021survey}.


%================= COMMENTS ========================
% While surveys naturally lend themselves as a basis for grouping similar users to create personas, they need human input to be designed and are hard to generalise for a variety of persona use-cases. Therefore, they do not apply to our project, because our intent is to fully automate the process.

% Our system proposes to fill this research gap by using social media data in order to gain insights on both demographics and behaviors, and not relying on previously collected analytics. As already mentioned, attention needs to be given to achieving GDPR compliance and to the way data is processed, since it is highly unstructured.